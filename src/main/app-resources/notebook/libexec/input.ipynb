{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## WFP-01-03-02 CHIRPS Rainfall Estimates (RFE) - Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This application generates Rainfall Estimates (RFE) aggregations, from CHIRPS RFE 5km resolution, compared to a reference period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"quicklink\">Quick link\n",
    "\n",
    "* [Objective](#objective)\n",
    "* [Test Site](#test-site)\n",
    "* [Context](#context)\n",
    "* [Applicability](#applicability)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [Strengths and Limitations](#strengths-limitations) \n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"objective\">Objective \n",
    "\n",
    "The objective of this code is to determine:\n",
    "    - Sum of daily data over the past N days, derived every 10 days (N = 10, 30, 60, 90, 120, 150, 180, 270, 365 days)\n",
    "    - Counts of daily data above 1mm over the past N days, derived every 10 days (N = 30, 60, 90 days).\n",
    "    - Longest sequence of daily values < 2mm (\"dry spell\") within the last N days, derived every 10 days (N = 30, 60, 90 days).\n",
    "\n",
    "### <a name=\"testsite\">Methodology\n",
    "\n",
    "We apply here the principles descrbed by [Hostache et al., 2012, Change detection approaches for flood extent mapping: How to select the most adequate reference image from online archives?](https://www.researchgate.net/publication/230627460_Change_detection_approaches_for_flood_extent_mapping_How_to_select_the_most_adequate_reference_image_from_online_archives)\n",
    "\n",
    "\n",
    "### <a name=\"testsite\">Test Site\n",
    "\n",
    "Mopti (Mali)\n",
    "\n",
    "### <a name=\"context\">Context\n",
    "\n",
    "The practice was applied to the flood event in Mopti in July 2016.\n",
    "\n",
    "### <a name=\"applicability\">Applicability\n",
    "\n",
    "This practice can be applied globally. It will be applied as input for a correlated search in the catalog allowing to identify rapidly a reference image for a flooding image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"data\">Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "SENTINEL data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. Radar data will be delivered within an hour of reception for Near Real-Time (NRT) emergency response, within three hours for NRT priority areas and within 24 hours for systematically archived data.\n",
    "\n",
    "All data products are distributed in the SENTINEL Standard Archive Format for Europe (SAFE) format.\n",
    "\n",
    "Data products are available in single polarisation (VV or HH) for Wave mode and dual polarisation (VV+VH or HH+HV) and single polarisation (HH or VV) for SM, IW and EW modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Level-1 Ground Range Detected (GRD) products consist of focused SAR data that has been detected, multi-looked and projected to ground range using an Earth ellipsoid model. Phase information is lost. The resulting product has approximately square resolution pixels and square pixel spacing with reduced speckle at the cost of reduced geometric resolution.\n",
    "\n",
    "GRD products can be in one of three resolutions:\n",
    "\n",
    "* Full Resolution (FR)\n",
    "* High Resolution (HR)\n",
    "* Medium Resolution (MR).\n",
    "\n",
    "The resolution is dependent upon the amount of multi-looking performed. Level-1 GRD products are available in MR and HR for IW and EW modes, MR for WV mode and MR, HR and FR for SM mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'CHIRPS Rainfall Estimates (RFE) - Aggregations'),\n",
    "                ('abstract', 'TBD'),\n",
    "                ('id', 'wfp-01-03-02')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the CHIRPS stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON((-30 -10, 20 -10, 20 40, -30 40, -30 -10))\n"
     ]
    }
   ],
   "source": [
    "#input_identifiers = ('chirps-v2.0.2018.09.28.tif.gz', 'chirps-v2.0.2018.09.27.tif.gz', 'chirps-v2.0.2018.09.26.tif.gz', 'chirps-v2.0.2018.09.25.tif.gz')\n",
    "input_identifiers = ['chirps-v2.0.2018.09.28.tif.gz']\n",
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                          ('value', 'POLYGON((-30 -10, 20 -10, 20 40, -30 40, -30 -10))'),\n",
    "                          ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                          ('abstract', 'Set the value of WKT Polygon')])\n",
    "print(regionOfInterest['value'])\n",
    "# region_of_interest = 'POLYGON((-30 -10, 20 -10, 20 40, -30 40, -30 -10))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the CHIRPS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input_references = ('ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/tifs/p05/2018/chirps-v2.0.2018.09.28.tif.gz', 'ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/tifs/p05/2018/chirps-v2.0.2018.09.27.tif.gz', 'ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/tifs/p05/2018/chirps-v2.0.2018.09.26.tif.gz', 'ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/tifs/p05/2018/chirps-v2.0.2018.09.25.tif.gz') \n",
    "input_references = ['ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/tifs/p05/2018/chirps-v2.0.2018.09.28.tif.gz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/data/chirps-2.0/\"\n",
    "unzipped_chirps_path = \"/workspace/data/chirps-2.0/unzipped_chirps/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import gzip\n",
    "import shutil\n",
    "import numpy as np\n",
    "from aux_functions import matrix_sum, mask_matrix, crop_image, write_output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON((-30 -10, 20 -10, 20 40, -30 40, -30 -10))\n",
      "<type 'list'>\n",
      "chirps-v2.0.2018.09.28.tif.gz\n",
      "ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/tifs/p05/2018/chirps-v2.0.2018.09.28.tif.gz\n",
      "(array([0, 1]), array([468737, 531263]))\n",
      "[  0.00000000e+00   1.56978928e-02   2.37863846e-02 ...,   6.91556320e+01\n",
      "   7.18521957e+01   8.91555023e+01]\n",
      "(array([0, 1]), array([894725, 105275]))\n",
      "(array([0, 1]), array([989149,  10851]))\n"
     ]
    }
   ],
   "source": [
    "products = []\n",
    "mask_no_data_value = 0\n",
    "sum_result = 0\n",
    "count_above_one = 0\n",
    "max_sequence = 0\n",
    "temp_mat = 0\n",
    "region_of_interest = regionOfInterest['value']\n",
    "print(region_of_interest)\n",
    "print(type(input_references))\n",
    "for chirp_product_url in input_references:\n",
    "    # uncompressed data\n",
    "    chirp_product = chirp_product_url.split('/')[-1]\n",
    "    print(chirp_product)\n",
    "    print(chirp_product_url)\n",
    "    # unzipped_product = unzipped_chirps_path + chirp_product.split('.gz')[0]\n",
    "    # with gzip.open(zipped_product, 'rb') as f_in:\n",
    "    #     with open(unzipped_product, 'wb') as f_out:\n",
    "    #         shutil.copyfileobj(f_in, f_out)\n",
    "    # Crop the image according to the region of interest\n",
    "    cropped_product_path = data_path + 'crop_' + chirp_product\n",
    "    crop_image(chirp_product_url, region_of_interest, cropped_product_path)\n",
    "    # Read GeoTIFF as an array\n",
    "    dataset = gdal.Open(cropped_product_path)\n",
    "    product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "    no_data_value = dataset.GetRasterBand(1).ComputeRasterMinMax()[0]\n",
    "    ## Create mask of no_data_values\n",
    "    if isinstance(mask_no_data_value, int):\n",
    "        mask_no_data_value = np.where(product_array == no_data_value, 1, 0)\n",
    "    else:\n",
    "        temp_mask = np.where(product_array == no_data_value, 1, 0)\n",
    "        mask_no_data_value = matrix_sum(mask_no_data_value, temp_mask)\n",
    "    \n",
    "    ## Create iteratively the sum array\n",
    "    sum_result = matrix_sum(sum_result, product_array, no_data_value)\n",
    "    \n",
    "    ## Create iteratively the array with the counts of daily data above 1mm\n",
    "    regions_above_one = mask_matrix(product_array, 1, True, no_data_value)\n",
    "    count_above_one = matrix_sum(count_above_one, regions_above_one)\n",
    "    \n",
    "    ## Create iteratively the array with the longest sequence of daily values <2mm\n",
    "    regions_below_two = mask_matrix(product_array, 2, False, no_data_value)\n",
    "    temp_mat = matrix_sum(temp_mat, regions_below_two)\n",
    "    if isinstance(max_sequence, int):\n",
    "        max_sequence = temp_mat\n",
    "    max_sequence[regions_below_two == 0] = np.maximum(max_sequence[regions_below_two == 0], temp_mat[regions_below_two == 0])\n",
    "    temp_mat[regions_below_two == 0] = 0\n",
    "    \n",
    "\n",
    "    \n",
    "print(np.unique(mask_no_data_value, return_counts=True))    \n",
    "print(np.unique(sum_result))\n",
    "print(np.unique(count_above_one, return_counts=True))\n",
    "print(np.unique(max_sequence, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "fig0 = pyplot.figure()\n",
    "ax0 = fig0.add_subplot(111)\n",
    "cax0 = ax0.matshow(sum_result)\n",
    "fig0.colorbar(cax0)\n",
    "\n",
    "fig1 = pyplot.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "cax1 = ax1.matshow(count_above_one)\n",
    "fig1.colorbar(cax1)\n",
    "\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(mask_no_data_value)\n",
    "fig.colorbar(cax)\n",
    "\n",
    "\n",
    "fig2 = pyplot.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "cax2 = ax2.matshow(max_sequence)\n",
    "fig2.colorbar(cax2)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Write Output GeoTIFFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "outpath = '/workspace/wfp-01-03-02/outputs/'\n",
    "image_format = \"GTiff\"\n",
    "num_days = len(input_identifiers)\n",
    "write_output_image(outpath + str(num_days) + 'days_total.tif', sum_result, image_format, mask_no_data_value)\n",
    "write_output_image(outpath + str(num_days) + 'days_above_one.tif', count_above_one, image_format, mask_no_data_value)\n",
    "write_output_image(outpath + str(num_days) + 'days_dry_spell.tif', max_sequence, image_format, mask_no_data_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
